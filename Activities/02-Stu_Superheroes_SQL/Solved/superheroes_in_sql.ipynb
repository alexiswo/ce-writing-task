{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "superheroes_in_sql.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ87Om9W21yE"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm0mnNcg1CNx"
      },
      "source": [
        "import os\n",
        "\n",
        "# Find the latest version of spark 2.0 from http://www-us.apache.org/dist/spark/ and update the line below if necessary\n",
        "spark_version = 'spark-2.4.7'\n",
        "os.environ['SPARK_VERSION'] = spark_version\n",
        "\n",
        "# Install dependencies: Spark, hadoop, Java, and Findspark\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weEc9FFh1K5d"
      },
      "source": [
        "# Set environment path in order to run PySpark in Google Colab\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2fg5gtM1XO8"
      },
      "source": [
        "# Create a local Spark session\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsP30FsNK-yo"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8_1OKZa2zvW"
      },
      "source": [
        "# Upload heroes_information.csv and super_hero_powers.csv files\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9jRA8FP3HSA"
      },
      "source": [
        "# Import data from both CSV files into DataFrames\n",
        "heroes = spark.read.load(\n",
        "    \"heroes_information.csv\",\n",
        "    format=\"csv\",\n",
        "    inferSchema=\"true\",\n",
        "    header=\"true\"\n",
        ")\n",
        "\n",
        "superpowers = spark.read.load(\n",
        "    \"super_hero_powers.csv\",\n",
        "    format=\"csv\",\n",
        "    inferSchema=\"true\",\n",
        "    header=\"true\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAJUYxzWix6p"
      },
      "source": [
        "# Create views from the DataFrames so that we can query our data in SQL\n",
        "heroes.createOrReplaceTempView(\"heroes\")\n",
        "superpowers.createOrReplaceTempView(\"superpowers\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EoqLRHih2kg"
      },
      "source": [
        "## Write SQL queries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UzatW_rwEAB"
      },
      "source": [
        "# Write a SQL query to return the name, eye color, and alignment of heroes that have an alignment of 'bad' or 'neutral' and the power of invisibility\n",
        "sqlSneakyInvisibles = spark.sql(\"\"\"\n",
        "SELECT heroes.name, heroes.`Eye color`, heroes.alignment\n",
        "FROM heroes\n",
        "JOIN superpowers ON heroes.name = superpowers.hero_names\n",
        "WHERE heroes.alignment IN ('bad', 'neutral')\n",
        "  AND superpowers.invisibility = True\n",
        "\"\"\")\n",
        "\n",
        "sqlSneakyInvisibles.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VChfZoSawECT"
      },
      "source": [
        "# Write a SQL query to return the top ten publishers by count of female heroes with the power of super strength\n",
        "sqlFemalesByPublisher = spark.sql(\"\"\"\n",
        "SELECT publisher, count(1)\n",
        "FROM heroes\n",
        "JOIN superpowers ON heroes.name = superpowers.hero_names\n",
        "WHERE heroes.gender = 'Female'\n",
        "  AND superpowers.`Super strength` = True\n",
        "GROUP BY heroes.publisher\n",
        "ORDER BY count(1) DESC\n",
        "LIMIT 10\n",
        "\"\"\")\n",
        "\n",
        "sqlFemalesByPublisher.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLr3uAU0wEGH"
      },
      "source": [
        "# Write a SQL query to return all of the heroes that exist in the heroes table but not the superpowers table\n",
        "sqlHeroesWithoutPowers = spark.sql(\"\"\"\n",
        "SELECT heroes.name\n",
        "FROM heroes\n",
        "LEFT JOIN superpowers ON heroes.name = superpowers.hero_names\n",
        "WHERE superpowers.hero_names IS NULL\n",
        "\"\"\")\n",
        "\n",
        "sqlHeroesWithoutPowers.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}